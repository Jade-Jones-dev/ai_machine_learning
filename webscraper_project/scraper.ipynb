{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54919c2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Page 1: Found 24 product blocks\n",
      "üîç Page 2: Found 24 product blocks\n",
      "üîç Page 3: Found 24 product blocks\n",
      "üîç Page 4: Found 24 product blocks\n",
      "üîç Page 5: Found 24 product blocks\n",
      "üîç Page 6: Found 24 product blocks\n",
      "üîç Page 7: Found 24 product blocks\n",
      "üîç Page 8: Found 24 product blocks\n",
      "üîç Page 9: Found 21 product blocks\n",
      "‚úÖ Finished scraping 213 unique product links\n",
      "‚úÖ Scraped 643 product variants with visible prices\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "# Set up headless browser\n",
    "options = Options()\n",
    "options.add_argument(\"--headless\")\n",
    "options.add_argument(\"--disable-gpu\")\n",
    "driver = webdriver.Chrome(options=options)\n",
    "\n",
    "search_base = \"https://justingredients.co.uk/search?q=herbs&page={}\"\n",
    "\n",
    "total_pages = 9 \n",
    "\n",
    "product_links = []  \n",
    "\n",
    "for page_num in range(1, total_pages + 1):\n",
    "    search_url = search_base.format(page_num)\n",
    "    driver.get(search_url)\n",
    "    time.sleep(3) \n",
    "\n",
    "    product_blocks = driver.find_elements(By.CLASS_NAME, \"collection-item\")\n",
    "    print(f\"Page {page_num}: Found {len(product_blocks)} product blocks\")\n",
    "\n",
    "    for block in product_blocks:\n",
    "        try:\n",
    "            link = block.get_attribute(\"href\")\n",
    "            name = block.text.strip()\n",
    "            if link and name:\n",
    "                product_links.append((name, link))\n",
    "            else:\n",
    "                print(f\"‚ö†Ô∏è Skipped block with missing link or name on page {page_num}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error parsing block on page {page_num}: {e}\")\n",
    "\n",
    "print(f\"Finished scraping {len(product_links)} unique product links\")\n",
    "\n",
    "results = []\n",
    "\n",
    "for name, link in product_links:\n",
    "    driver.get(link)\n",
    "    time.sleep(2)\n",
    "    try:\n",
    "        \n",
    "        rows = driver.find_elements(By.CSS_SELECTOR, 'tr')\n",
    "\n",
    "        for row in rows:\n",
    "            try:\n",
    "                size_cell = row.find_element(By.CSS_SELECTOR, 'td[data-label=\"Size\"]')\n",
    "                price_divs = row.find_elements(By.CSS_SELECTOR, 'td[data-label=\"Price\"] div.price')\n",
    "\n",
    "                combined_price_text = \" \".join([div.text.strip() for div in price_divs]).strip()\n",
    "\n",
    "                raw_prices = combined_price_text.split()\n",
    "\n",
    "                unique_prices = list(dict.fromkeys(raw_prices))\n",
    "\n",
    "                numeric_prices = []\n",
    "                for p in unique_prices:\n",
    "                    try:\n",
    "                        numeric_prices.append(float(p.replace(\"¬£\", \"\").strip()))\n",
    "                    except:\n",
    "                        continue\n",
    "\n",
    "                regular_price = sale_price = None\n",
    "\n",
    "                if len(numeric_prices) == 1:\n",
    "                    regular_price = sale_price = f\"¬£{numeric_prices[0]:.2f}\"\n",
    "                elif len(numeric_prices) == 2:\n",
    "                    high, low = max(numeric_prices), min(numeric_prices)\n",
    "                    regular_price = f\"¬£{high:.2f}\"\n",
    "                    sale_price = f\"¬£{low:.2f}\"\n",
    "\n",
    "                price = combined_price_text\n",
    "                size = size_cell.text.strip()\n",
    "\n",
    "                results.append({\n",
    "                    \"name\": name,\n",
    "                    \"url\": link,\n",
    "                    \"variant\": size,\n",
    "                    \"regular_price\": regular_price,\n",
    "                    \"sale_price\": sale_price,\n",
    "                    \"scraped_at\": datetime.now().isoformat()\n",
    "                })\n",
    "            except Exception as e:\n",
    "                continue\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Could not parse {link}: {e}\")\n",
    "        continue\n",
    "\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "# Save to CSV\n",
    "df = pd.DataFrame(results)\n",
    "df.to_csv(\"herb_prices.csv\", index=False)\n",
    "print(f\"Scraped {len(df)} product variants with visible prices\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
